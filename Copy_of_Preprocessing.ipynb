{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Copy_of_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuEeyqzznnZm"
      },
      "source": [
        "# Adding Images to Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      },
      "source": [
        "## Getting Day Sequence Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEDG2AtYhNL",
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ],
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      },
      "source": [
        "## Getting Clip Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "outputs": [],
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTkEFu_78tCf"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GziBHlH4g5"
      },
      "source": [
        "# Adding All Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdQUObMsW-Q"
      },
      "source": [
        "## Getting all Sequence Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrV_68rxug_v"
      },
      "source": [
        "## Getting all Clip Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "outputs": [],
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2KCYipPzis"
      },
      "source": [
        "# Sorting All Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKRu9hLzs1V"
      },
      "source": [
        "# Cropping the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "outputs": [],
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDgT7CPTUYb"
      },
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "664d2a46-7d2f-4d4e-c070-ba54183427ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "outputs": [],
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# folder = '/Users/manavgurnani21/Downloads/content/all_images_randomized/val/warningLeft'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAXf-3LMzxTk"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "# setting paths\n",
        "folder_raw = '/Users/manavgurnani21/Downloads/cropped_images_raw/'\n",
        "folder_augmented = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/'\n",
        "folder_final = '/Users/manavgurnani21/Downloads/content/all_images_randomized/'\n",
        "\n",
        "# used to get paths of all folders we are going to move into the big folder\n",
        "all_sub_paths = []\n",
        "\n",
        "# all class names\n",
        "all_class_names = ['go', 'stopLeft', 'warningLeft', 'goForward', 'stop', 'warning', 'goLeft']\n",
        "\n",
        "# for file in os.listdir(folder_raw):\n",
        "#     print(file)\n",
        "\n",
        "# getting paths of all sub  folders to copy\n",
        "for filename in os.listdir(folder_raw):\n",
        "    if '.DS_Store' not in filename:\n",
        "        file_path = os.path.join(folder_raw, filename)\n",
        "        for classifier in os.listdir(file_path):\n",
        "            if '.DS_Store' not in classifier:\n",
        "                all_sub_paths.append(os.path.join(file_path, classifier))\n",
        "\n",
        "for filename in os.listdir(folder_augmented):\n",
        "    if '.DS_Store' not in filename:\n",
        "        file_path = os.path.join(folder_augmented, filename)\n",
        "        for classifier in os.listdir(file_path):\n",
        "            if '.DS_Store' not in classifier:\n",
        "                all_sub_paths.append(os.path.join(file_path, classifier))\n",
        "\n",
        "# creating base test train val folders\n",
        "# os.mkdir('/Users/manavgurnani21/Downloads/content/all_images_randomized/train')\n",
        "# os.mkdir('/Users/manavgurnani21/Downloads/content/all_images_randomized/test')\n",
        "# os.mkdir('/Users/manavgurnani21/Downloads/content/all_images_randomized/val')\n",
        "\n",
        "# for folder in os.listdir(folder_final):\n",
        "#     for name in all_class_names:\n",
        "#         os.mkdir(folder_final + folder + '/' + name)\n",
        "\n",
        "for item in all_sub_paths:\n",
        "    for image in os.listdir(item):\n",
        "        directories = item.split('/')\n",
        "        src = item + '/' + image\n",
        "        dst = folder_final + directories[-2] + '/' + directories[-1] + '/'\n",
        "        shutil.copy2(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Labels"
      ],
      "metadata": {
        "id": "c6BOoVsAnaci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip'"
      ],
      "metadata": {
        "id": "HhqyKfBxnswb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rgPasQnfnltR"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + '/' + folder)\n",
        "  return pathList"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "all_image_path_test_labels = []\n",
        "\n",
        "for folder in listPaths('/content/content/cropped_images_randomized/train'):\n",
        "    if folder != '/content/content/cropped_images_randomized/train/.DS_Store':\n",
        "        for file in os.listdir(folder):\n",
        "          all_image_path_test_labels.append(folder.split('/')[-1])"
      ],
      "metadata": {
        "id": "UyPOKprWneQA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(os.listdir('/content/content/cropped_images_randomized/train/go'))\n",
        "print(all_image_path_test_labels)"
      ],
      "metadata": {
        "id": "_mmVPxC4svvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7P7n0GRQQG"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAsoBnr-zxTl"
      },
      "outputs": [],
      "source": [
        "# There are several ways you can enhance your image detection model:\n",
        "\n",
        "# Use a more powerful model architecture: There are many different model architectures that can be used for image detection, such as VGG, ResNet, and Inception. Using a more powerful architecture can help your model learn more discriminative features and improve performance.\n",
        "\n",
        "# Fine-tune a pre-trained model: Pre-trained models have already been trained on a large dataset and can be fine-tuned for your specific task. Fine-tuning can help your model learn task-specific features and improve performance.\n",
        "\n",
        "# Use transfer learning: Transfer learning involves using the features learned by a pre-trained model and applying them to a new task. This can be an effective way to improve performance on a new task, particularly if you have a limited amount of training data.\n",
        "\n",
        "# Experiment with different hyperparameters: Hyperparameters are settings that determine the model's behavior and performance. You can try tuning different hyperparameters, such as the learning rate, batch size, and optimization algorithm, to see if they have an impact on your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo_a0Vv2zxTl"
      },
      "outputs": [],
      "source": [
        "# # importing the modules\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# # Providing the folder path\n",
        "# origin = '/Users/manavgurnani21/Downloads/content 2/cropped_images_non_augmented/train/go/'\n",
        "# target = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train/go/'\n",
        "\n",
        "# # Fetching the list of all the files\n",
        "# files = os.listdir(origin)\n",
        "\n",
        "# shutil.copy2(origin, '/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/random')\n",
        "\n",
        "# print(files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the data for each class\n",
        "go_freq = all_image_path_test_labels.count('go')\n",
        "goForward_freq = all_image_path_test_labels.count('goForward')\n",
        "goLeft_freq = all_image_path_test_labels.count('goLeft')\n",
        "stop_freq = all_image_path_test_labels.count('stop')\n",
        "stopLeft_freq = all_image_path_test_labels.count('stopLeft')\n",
        "warning_freq = all_image_path_test_labels.count('warning')\n",
        "warningLeft_freq = all_image_path_test_labels.count('warningLeft')\n",
        "\n",
        "total = len(all_image_path_test_labels)\n",
        "\n",
        "# Combine the data into a single list\n",
        "data = [go_freq/total, goForward_freq/total, goLeft_freq/total, stop_freq/total, stopLeft_freq/total, warning_freq/total, warningLeft_freq/total]\n",
        "\n",
        "# Define the labels for each class\n",
        "labels = ['Go', 'Go Forward', 'Go Left', 'Stop', 'Stop Left', 'Warning', 'Warning Left']\n",
        "\n",
        "# Create the histogram\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "# Plot the data\n",
        "ax.bar(labels, data)\n",
        "\n",
        "# Add title and labels\n",
        "ax.set_title('Class Frequency Histogram')\n",
        "ax.set_xlabel('Class')\n",
        "ax.set_ylabel('Frequency')\n",
        "\n",
        "# Show the graph\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "QweyqTTNpXN3",
        "outputId": "0d66a7e6-4683-4934-e2b3-2e6df47637f6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xwcfMd8aFeJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94e5bd7b-db13-45d5-ae77-e819e32c203c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/content/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/content/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/content/content/cropped_images_randomized/val'\n",
        " \n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size= 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_class_names = test_ds.class_names\n",
        "print(test_class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufBctosMoe1X",
        "outputId": "1028397c-54fc-4abe-9488-f2b81a400f50"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulhOh93SA-C",
        "outputId": "12d584e1-2e47-46f7-dd8e-d13ee382cc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B998lB9ZSRpr",
        "outputId": "86f9f877-2f07-40a7-8fb5-9dc76bbc7e0b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 255.0\n"
          ]
        }
      ],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(train_ds))\n",
        "first_image = image_batch[0]\n",
        "first_label = labels_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of unique labels\n",
        "num_classes = 7\n",
        "\n",
        "# Define a function to one-hot encode the labels\n",
        "def one_hot_encode(y):\n",
        "    return tf.one_hot(y, depth=num_classes)\n",
        "\n",
        "# Use the map method to apply the one-hot encoding function to each batch of labels\n",
        "encoded_ds = normalized_ds.map(lambda x, y: (x, one_hot_encode(y)))"
      ],
      "metadata": {
        "id": "pWcjwkeL-eYe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(encoded_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "npLLgKpMy-17",
        "outputId": "874c2fd4-f870-4184-e271-579e2b2e85fa"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.dataset_ops.MapDataset"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras import backend as K\n",
        "\n",
        "# Compute the class weights\n",
        "weights = np.asarray([1/(go_freq/total), 1/(goForward_freq/total), 1/(goLeft_freq/total), 1/(stop_freq/total), 1/(stopLeft_freq/total), 1/(warning_freq/total), 1/(warningLeft_freq/total)])\n",
        "\n",
        "# np_1 = np.asarray([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
        "# np_2 = np.asarray([0.1, 0.4, 0.1, 0.1, 0.2, 0.1, 0.1])\n",
        "\n",
        "# Define the weighted cross-entropy loss function\n",
        "# def loss(y_true, y_pred):\n",
        "#   # scale predictions so that the class probas of each sample sum to 1\n",
        "#   y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "#   # clip to prevent NaN's and Inf's\n",
        "#   y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "#   # calc\n",
        "#   loss = y_true * K.log(y_pred) * weights\n",
        "#   loss = -K.sum(loss, -1)\n",
        "#   return loss\n",
        "\n",
        "# loss(np_1, np_2)"
      ],
      "metadata": {
        "id": "2I6nmp687fJ1"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7sVEo5KVSTr4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k8dcy2-zxTm"
      },
      "source": [
        "# ResNet 50\n",
        "\n",
        "Accuracy: 0.34203296703296704"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCeN1v5PzxTm",
        "outputId": "bc7a2675-1bad-4ad8-caf3-d170a5aa6f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 4s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=7,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "BiEFPD6-Sfgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51635a91-5883-4a0a-8939-f406b4ddee64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,640,391\n",
            "Trainable params: 1,052,679\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "outputs": [],
      "source": [
        "# vgg_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "class_weights = {'dense_1' : 1/(go_freq/total)}\n",
        "# class_weights = [1/(go_freq/total), 1/(goForward_freq/total), 1/(goLeft_freq/total), 1/(stop_freq/total), 1/(stopLeft_freq/total), 1/(warning_freq/total), 1/(warningLeft_freq/total)]\n",
        "\n",
        "resnet_model.compile(optimizer='Adam', loss = tf.nn.weighted_cross_entropy_with_logits, loss_weights=class_weights, weighted_metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 728
        },
        "id": "moEFn9SzSoFn",
        "outputId": "7b9f4c20-60fa-4ae9-8c83-d945be459940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d755d59f0b47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m resnet_history = resnet_model.fit(\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 152, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/losses.py\", line 284, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n\n    TypeError: Missing required positional argument\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True)\n",
        "\n",
        "resnet_history = resnet_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=50,\n",
        "  callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjyWDkCozxTn",
        "outputId": "72496cc9-fc3c-4d48-bf75-e5293895c929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n"
          ]
        }
      ],
      "source": [
        "print(len(resnet_history.history['loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rkIb-0bzxTn"
      },
      "outputs": [],
      "source": [
        "# resnet_model = keras.models.load_model('/Users/manavgurnani21/Downloads/Trained_Models/Experiment_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4-bmNNnyqeZ",
        "outputId": "5bd1c2ed-dd69-420b-b8e7-17ed8a57e891",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "160/160 [==============================] - 24s 150ms/step\n",
            "[3.86867323e-25 3.70493393e-38 1.04675324e-21 1.48433354e-08\n",
            " 1.00000000e+00 8.22805189e-27 1.06066992e-19]\n"
          ]
        }
      ],
      "source": [
        "pred=resnet_history.model.predict(test_ds)\n",
        "print(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeZbnghpzxTn",
        "outputId": "34201fe0-9216-4f86-cd63-8914fd6a4fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(resnet_history.history['accuracy'])\n",
        "plt.plot(resnet_history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAi_ibGazxTn",
        "outputId": "eadf9a1f-66cc-41a4-b68c-13563cccb887",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-0d3369065659>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_output\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpred_np\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mcorrect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   7213\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7214\u001b[0m   \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7215\u001b[0;31m   \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:GPU:0}} slice index 5096 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "pred_np = np.asarray(pred)\n",
        "\n",
        "correctPred = 0\n",
        "predicted = []\n",
        "correct = []\n",
        "for image_output in pred_np:\n",
        "    predicted.append(np.argmax(image_output))\n",
        "    correct.append(labels_batch[i].numpy())\n",
        "\n",
        "i = 0\n",
        "for prediction in predicted:\n",
        "  if(predicted[i] == correct[i]):\n",
        "        correctPred += 1\n",
        "  i += 1\n",
        "\n",
        "print(correctPred)\n",
        "# accuracy = correct / len(all_image_path_test_labels)\n",
        "\n",
        "# print(\"The accuracy of this model is:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wsZUHD0zxTn"
      },
      "outputs": [],
      "source": [
        "# from keras.models import save_model\n",
        "\n",
        "# keras.models.save_model(resnet_model,'/Users/manavgurnani21/Downloads/Trained_Models/Experiment_16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj5YNyOnf6X"
      },
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAUH9_HuzxTo"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSl-f8ytzxTo",
        "outputId": "b109a90d-c81d-436c-e63c-a0f5fa3f4ec8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_6612/1493919654.py:12: FutureWarning: `multichannel` is a deprecated argument name for `match_histograms`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  matched = match_histograms(image, reference, multichannel=True)\n",
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_6612/1285761232.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  log_image = c * (np.log(image + 1))\n"
          ]
        }
      ],
      "source": [
        "# import required module\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def applyTransformation(directory):\n",
        "    # iterate over files in\n",
        "    # that directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if(filename.__contains__('.DS_Store') == False):\n",
        "                img2 = cv2.imread(os.path.join(root, filename))\n",
        "                new = specification(os.path.join(root, filename))\n",
        "                new_2 = histogram_equalization(new)\n",
        "                new_3 = log_inverse(new_2)\n",
        "                new_4 = gamma(new_3, 0.25)\n",
        "                cv2.imwrite(os.path.join(root, filename), new_4)\n",
        "\n",
        "applyTransformation('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9cEt6ANzxTo"
      },
      "source": [
        "## Experiment 1: Hist. Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haAJTVsdzxTo"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c80b5wOzxTo"
      },
      "source": [
        "## Experiment 2: Logarithm and Inverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfid6BIIzxTo"
      },
      "outputs": [],
      "source": [
        "def log_inverse(image):\n",
        "    c = 255 / np.log(1 + np.max(image))\n",
        "    log_image = c * (np.log(image + 1))\n",
        "    \n",
        "    # Specify the data type so that\n",
        "    # float value will be converted to int\n",
        "    log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "    img = cv2.cvtColor(log_image, cv2.COLOR_BGR2RGB)\n",
        "    colored_negative = abs(255-img)\n",
        "    return colored_negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlTvZQVnzxTo"
      },
      "source": [
        "## Experiment 3: Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1E-EoWczxTo"
      },
      "outputs": [],
      "source": [
        "def gamma(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        "\n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        "\n",
        "    return cv2.LUT(src, table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWbvnUrLzxTo"
      },
      "source": [
        "## Experiment 4: Specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONl9ErjtzxTo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from PIL import Image\n",
        "\n",
        "def specification(path):\n",
        "    reference_unsized = cv2.cvtColor(cv2.imread('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/Colour-Wheel-Rainbow-Spectrum-Color-Wheel-1740381.jpg'), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    reference = cv2.resize(reference_unsized, (image.shape[1], image.shape[0]))\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7dd6fc5c128be82ef760667744b68c23ef537939cb516a15f2e77205952262b8"
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}