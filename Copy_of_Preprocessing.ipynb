{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Copy_of_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuEeyqzznnZm"
      },
      "source": [
        "# Adding Images to Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdjgiM_BXF-o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "8d8c5abb-7431-49fe-d146-c1df223b70f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-95305d3f-1124-46fa-bc82-a3d74ef8117b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-95305d3f-1124-46fa-bc82-a3d74ef8117b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-779470458578>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mkdir ~/.kaggle'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    154\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    155\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      },
      "source": [
        "## Getting Day Sequence Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uGEDG2AtYhNL"
      },
      "outputs": [],
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bF2_X1ZQf6Zy"
      },
      "outputs": [],
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      },
      "source": [
        "## Getting Clip Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "outputs": [],
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTkEFu_78tCf"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GziBHlH4g5"
      },
      "source": [
        "# Adding All Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdQUObMsW-Q"
      },
      "source": [
        "## Getting all Sequence Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrV_68rxug_v"
      },
      "source": [
        "## Getting all Clip Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "outputs": [],
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2KCYipPzis"
      },
      "source": [
        "# Sorting All Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKRu9hLzs1V"
      },
      "source": [
        "# Cropping the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "outputs": [],
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nnl9YYrgMvZv"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDgT7CPTUYb"
      },
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTjvPhm8EKyN"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "outputs": [],
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# folder = '/Users/manavgurnani21/Downloads/content/all_images_randomized/val/warningLeft'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAXf-3LMzxTk"
      },
      "outputs": [],
      "source": [
        "import os, shutil\n",
        "\n",
        "# setting paths\n",
        "folder_raw = '/Users/manavgurnani21/Downloads/cropped_images_raw/'\n",
        "folder_augmented = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/'\n",
        "folder_final = '/Users/manavgurnani21/Downloads/content/all_images_randomized/'\n",
        "\n",
        "# used to get paths of all folders we are going to move into the big folder\n",
        "all_sub_paths = []\n",
        "\n",
        "# all class names\n",
        "all_class_names = ['go', 'stopLeft', 'warningLeft', 'goForward', 'stop', 'warning', 'goLeft']\n",
        "\n",
        "# for file in os.listdir(folder_raw):\n",
        "#     print(file)\n",
        "\n",
        "# getting paths of all sub  folders to copy\n",
        "for filename in os.listdir(folder_raw):\n",
        "    if '.DS_Store' not in filename:\n",
        "        file_path = os.path.join(folder_raw, filename)\n",
        "        for classifier in os.listdir(file_path):\n",
        "            if '.DS_Store' not in classifier:\n",
        "                all_sub_paths.append(os.path.join(file_path, classifier))\n",
        "\n",
        "for filename in os.listdir(folder_augmented):\n",
        "    if '.DS_Store' not in filename:\n",
        "        file_path = os.path.join(folder_augmented, filename)\n",
        "        for classifier in os.listdir(file_path):\n",
        "            if '.DS_Store' not in classifier:\n",
        "                all_sub_paths.append(os.path.join(file_path, classifier))\n",
        "\n",
        "# creating base test train val folders\n",
        "# os.mkdir('/Users/manavgurnani21/Downloads/content/all_images_randomized/train')\n",
        "# os.mkdir('/Users/manavgurnani21/Downloads/content/all_images_randomized/test')\n",
        "# os.mkdir('/Users/manavgurnani21/Downloads/content/all_images_randomized/val')\n",
        "\n",
        "# for folder in os.listdir(folder_final):\n",
        "#     for name in all_class_names:\n",
        "#         os.mkdir(folder_final + folder + '/' + name)\n",
        "\n",
        "for item in all_sub_paths:\n",
        "    for image in os.listdir(item):\n",
        "        directories = item.split('/')\n",
        "        src = item + '/' + image\n",
        "        dst = folder_final + directories[-2] + '/' + directories[-1] + '/'\n",
        "        shutil.copy2(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test Labels\n",
        "\n",
        "Downloading, unzipping, and receiving dataset."
      ],
      "metadata": {
        "id": "c6BOoVsAnaci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip'\n",
        "\n",
        "# !unzip '/content/cropped_images_randomized.zip'"
      ],
      "metadata": {
        "id": "HhqyKfBxnswb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgPasQnfnltR"
      },
      "outputs": [],
      "source": [
        "# getting the paths for all images in any folder\n",
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + '/' + folder)\n",
        "  return pathList"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting the class names for each image in order ()\n",
        "import os\n",
        "all_image_path_train_labels = []\n",
        "all_image_path_test_labels = []\n",
        "\n",
        "for folder in listPaths('/content/content/cropped_images_randomized/train'):\n",
        "    if folder != '/content/content/cropped_images_randomized/train/.DS_Store':\n",
        "        for file in os.listdir(folder):\n",
        "          all_image_path_train_labels.append(folder.split('/')[-1])\n",
        "\n",
        "for folder in listPaths('/content/content/cropped_images_randomized/test'):\n",
        "    if folder != '/content/content/cropped_images_randomized/test/.DS_Store':\n",
        "        for file in os.listdir(folder):\n",
        "          all_image_path_test_labels.append(folder.split('/')[-1])"
      ],
      "metadata": {
        "id": "UyPOKprWneQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(all_image_path_train_labels)"
      ],
      "metadata": {
        "id": "_mmVPxC4svvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7P7n0GRQQG"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAsoBnr-zxTl"
      },
      "outputs": [],
      "source": [
        "# There are several ways you can enhance your image detection model:\n",
        "\n",
        "# Use a more powerful model architecture: There are many different model architectures that can be used for image detection, such as VGG, ResNet, and Inception. Using a more powerful architecture can help your model learn more discriminative features and improve performance.\n",
        "\n",
        "# Fine-tune a pre-trained model: Pre-trained models have already been trained on a large dataset and can be fine-tuned for your specific task. Fine-tuning can help your model learn task-specific features and improve performance.\n",
        "\n",
        "# Use transfer learning: Transfer learning involves using the features learned by a pre-trained model and applying them to a new task. This can be an effective way to improve performance on a new task, particularly if you have a limited amount of training data.\n",
        "\n",
        "# Experiment with different hyperparameters: Hyperparameters are settings that determine the model's behavior and performance. You can try tuning different hyperparameters, such as the learning rate, batch size, and optimization algorithm, to see if they have an impact on your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jo_a0Vv2zxTl"
      },
      "outputs": [],
      "source": [
        "# # importing the modules\n",
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# # Providing the folder path\n",
        "# origin = '/Users/manavgurnani21/Downloads/content 2/cropped_images_non_augmented/train/go/'\n",
        "# target = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train/go/'\n",
        "\n",
        "# # Fetching the list of all the files\n",
        "# files = os.listdir(origin)\n",
        "\n",
        "# shutil.copy2(origin, '/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/random')\n",
        "\n",
        "# print(files)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # getting the frequencies for setting the initial class weights and the distribution of the images in each class\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "# # Define the data for each class\n",
        "# go_freq = all_image_path_test_labels.count('go')\n",
        "# goForward_freq = all_image_path_test_labels.count('goForward')\n",
        "# goLeft_freq = all_image_path_test_labels.count('goLeft')\n",
        "# stop_freq = all_image_path_test_labels.count('stop')\n",
        "# stopLeft_freq = all_image_path_test_labels.count('stopLeft')\n",
        "# warning_freq = all_image_path_test_labels.count('warning')\n",
        "# warningLeft_freq = all_image_path_test_labels.count('warningLeft')\n",
        "\n",
        "# total = len(all_image_path_test_labels)\n",
        "\n",
        "# # Combine the data into a single list\n",
        "# data = [go_freq/total, goForward_freq/total, goLeft_freq/total, stop_freq/total, stopLeft_freq/total, warning_freq/total, warningLeft_freq/total]\n",
        "\n",
        "# # Define the labels for each class\n",
        "# labels = ['Go', 'Go Forward', 'Go Left', 'Stop', 'Stop Left', 'Warning', 'Warning Left']\n",
        "\n",
        "# # Create the histogram\n",
        "# fig = plt.figure()\n",
        "# ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "# # Plot the data\n",
        "# ax.bar(labels, data)\n",
        "\n",
        "# # Add title and labels\n",
        "# ax.set_title('Class Frequency Histogram')\n",
        "# ax.set_xlabel('Class')\n",
        "# ax.set_ylabel('Frequency')\n",
        "\n",
        "# # Show the graph\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "QweyqTTNpXN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xwcfMd8aFeJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094da161-f9cf-436d-8ae6-f28c756a128a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n",
            "Found 40757 images belonging to 7 classes.\n",
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "# making the train test and validation split from the 'content' directory\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/content/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/content/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/content/content/cropped_images_randomized/val'\n",
        "\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size= 32\n",
        "\n",
        "# train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#   train_data_dir,\n",
        "#   seed=123,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "# Load the images from the directory and convert them to a numpy array\n",
        "train_data = ImageDataGenerator().flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(180, 180),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Get the numpy array of images and labels\n",
        "images, labels = train_data.next()\n",
        "\n",
        "images = np.asarray(images)\n",
        "labels = np.asarray(labels)\n",
        "\n",
        "# Print the shape of the numpy arrays\n",
        "print(type(images))  # should print (32, 180, 180, 3)\n",
        "print(type(labels))  # should print (32, num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Oversampling\n",
        "\n",
        "- rotating images between -5 and 5 degrees\n",
        "- scaling images from 0.9 to 1.1"
      ],
      "metadata": {
        "id": "eMuPqJxfA6nL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "import torch\n",
        "import numpy as np\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.over_sampling import ADASYN\n",
        "\n",
        "# print(len(os.listdir('/content/content/cropped_images_randomized/val')))\n",
        "\n",
        "# for end_class in os.listdir('/content/content/cropped_images_randomized/val'):\n",
        "#   print(end_class + \": \" + str(len(os.listdir('/content/content/cropped_images_randomized/val/' + end_class))))\n",
        "\n",
        "# def getMaxNumImages(path):\n",
        "#   numImagesInClass = []\n",
        "#   for end_class in os.listdir(path):\n",
        "#     print(end_class + \": \" + str(len(os.listdir(path + end_class))))\n",
        "#     numImagesInClass.append(len(os.listdir(path + end_class)))\n",
        "#   return max(numImagesInClass)\n",
        "\n",
        "# getMaxNumImages('/content/content/cropped_images_randomized/val/')\n",
        "\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "img_depth = 3\n",
        "batch_size= 32\n",
        "\n",
        "X = images.reshape((-1, 180*180*3))\n",
        "smote = SMOTE(sampling_strategy='minority')\n",
        "# adasyn = ADASYN(sampling_strategy='minority')\n",
        "oversample = RandomOverSampler(sampling_strategy='minority')\n",
        "X_resampled, y_resampled = oversample.fit_resample(X, labels)\n",
        "\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_resampled, y_resampled))\n",
        "train_ds = train_ds.map(lambda x, y: tf.reshape(x, [img_width, img_height, img_depth]))\n",
        "train_ds = train_ds.shuffle(buffer_size=len(X_resampled)).batch(batch_size)"
      ],
      "metadata": {
        "id": "KtoDE8L3BRxc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B998lB9ZSRpr"
      },
      "outputs": [],
      "source": [
        "# normalizing the images and the first layer to fit the images\n",
        "\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "# image_batch, labels_batch = next(iter(train_ds))\n",
        "# first_image = image_batch[0]\n",
        "# first_label = labels_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "# print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the number of unique labels\n",
        "num_classes = 7\n",
        "\n",
        "# Define a function to one-hot encode the labels\n",
        "def one_hot_encode(y):\n",
        "    return tf.one_hot(y, depth=num_classes)\n",
        "\n",
        "# Use the map method to apply the one-hot encoding function to each batch of labels\n",
        "# encoded_ds = normalized_ds.map(lambda x, y: (x, one_hot_encode(y)))"
      ],
      "metadata": {
        "id": "pWcjwkeL-eYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# import numpy as np\n",
        "# from keras import backend as K\n",
        "\n",
        "# Compute the class weights\n",
        "# weights = np.asarray([1/(go_freq/total), 1/(goForward_freq/total), 1/(goLeft_freq/total), 1/(stop_freq/total), 1/(stopLeft_freq/total), 1/(warning_freq/total), 1/(warningLeft_freq/total)])\n",
        "\n",
        "# np_1 = np.asarray([0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0])\n",
        "# np_2 = np.asarray([0.1, 0.4, 0.1, 0.1, 0.2, 0.1, 0.1])\n",
        "\n",
        "# Define the weighted cross-entropy loss function (DO NOT NEED BECAUSE WE ARE USING TF'S FUNCTION)\n",
        "# def loss(y_true, y_pred):\n",
        "#   # scale predictions so that the class probas of each sample sum to 1\n",
        "#   y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "#   # clip to prevent NaN's and Inf's\n",
        "#   y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "#   # calc\n",
        "#   loss = y_true * K.log(y_pred) * weights\n",
        "#   loss = -K.sum(loss, -1)\n",
        "#   return loss\n",
        "\n",
        "# loss(np_1, np_2)"
      ],
      "metadata": {
        "id": "2I6nmp687fJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sVEo5KVSTr4"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.utils import class_weight"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "Mosd2C-bm7AD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5k8dcy2-zxTm"
      },
      "source": [
        "# ResNet 50\n",
        "\n",
        "Building neural network and training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SCeN1v5PzxTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee72c27f-43f8-42d6-fb4c-c782942e0d22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=7,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BiEFPD6-Sfgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "520d20a0-643c-493c-9e3b-2cb368ad8256"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,640,391\n",
            "Trainable params: 1,052,679\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "def weighted_categorical_crossentropy(weights):\n",
        "    \"\"\"\n",
        "    A weighted version of keras.objectives.categorical_crossentropy\n",
        "\n",
        "    Variables:\n",
        "        weights: numpy array of shape (C,) where C is the number of classes\n",
        "\n",
        "    Usage:\n",
        "        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n",
        "        loss = weighted_categorical_crossentropy(weights)\n",
        "        model.compile(loss=loss,optimizer='adam')\n",
        "    \"\"\"\n",
        "\n",
        "    weights = K.variable(weights)\n",
        "\n",
        "    def loss(y_true, y_pred):\n",
        "        print(y_true)\n",
        "        y_true = one_hot_encode(y_true)\n",
        "        print(y_pred)\n",
        "        print(weights)\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss_true = -K.sum(loss, -1)\n",
        "        return loss_true\n",
        "\n",
        "    return loss\n",
        "\n",
        "# y_true = tf.convert_to_tensor(np.array([0, 1, 0, 0]))\n",
        "# y_pred = tf.convert_to_tensor(np.array([-18.6, 0.51, 2.94, -12.8]))\n",
        "# class_weights = [1, 1, 1, 1, 1, 1, 1]\n",
        "# bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# print(bce(y_true, y_pred).numpy())\n",
        "# print((weighted_categorical_crossentropy(y_true, y_pred, class_weights)))"
      ],
      "metadata": {
        "id": "YZwv_4OMIQQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Step 1: compute the number of instances for each class\n",
        "class_counts = [18626, 159, 1874, 18591, 10367, 1106, 228]\n",
        "N = sum(class_counts)\n",
        "\n",
        "# Step 2: compute the empirical distribution of each class\n",
        "class_distribution = [count / N for count in class_counts]\n",
        "\n",
        "# Step 3: compute the expected loss for each class\n",
        "def loss_function(i, j, distribution):\n",
        "    if i == j:\n",
        "        return -np.log(distribution[j])\n",
        "    else:\n",
        "        return -np.log(1-distribution[j])\n",
        "\n",
        "expected_loss = []\n",
        "for i in range(len(class_counts)):\n",
        "    loss = 0\n",
        "    for j in range(len(class_counts)):\n",
        "        loss += class_distribution[j] * loss_function(i, j, class_distribution)\n",
        "    expected_loss.append(loss)\n",
        "\n",
        "# Step 4: compute the weight for each class\n",
        "class_weights = [1 / np.sqrt(l) for l in expected_loss]\n",
        "print(class_weights)"
      ],
      "metadata": {
        "id": "OPqnA3lc4QNe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "184a172f-5c6c-4e97-9d61-22d3089a608e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1.311168735143627, 1.584821667513439, 1.4138638939277697, 1.3103777448742893, 1.2329410854948, 1.469933476990528, 1.57264307030534]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i8jrXpwvSkIS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a80c60-1fd3-4cf1-92e1-be17d4733444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ],
      "source": [
        "# setting the initial class weights and compiling the network\n",
        "# class_weights = {'dense_1' : 1/(go_freq/total), 'dense_2' : 1/(goForward_freq/total), 'dense_3' : 1/(goLeft_freq/total), 'dense_4' : 1/(stop_freq/total), 'dense_5' : 1/(stopLeft_freq/total), 'dense_6' : 1/(warning_freq/total), 'warningLeft' : 1/(warningLeft_freq/total)}\n",
        "# class_weights = tf.constant([0.01324651, 0.15182218, 0.01278938, 0.01327909, 0.02388292, 0.22484979, 0.55932912])\n",
        "# class_weights = [1/(go_freq/total), 1/(goForward_freq/total), 1/(goLeft_freq/total), 1/(stop_freq/total), 1/(stopLeft_freq/total), 1/(warning_freq/total), 1/(warningLeft_freq/total)]\n",
        "class_weights = [1, 1, 1, 1, 1, 1, 1]\n",
        "# class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(all_image_path_train_labels), y=all_image_path_train_labels)\n",
        "# class_weights = [1 / np.sqrt(l) for l in expected_loss]\n",
        "print(class_weights)\n",
        "\n",
        "resnet_model.compile(optimizer='Adam', loss = tf.losses.SparseCategoricalCrossentropy, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(class_weights)"
      ],
      "metadata": {
        "id": "6AWPWihH__VC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a5eed35-cb1b-49ba-ba6a-5a955ebbd89c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moEFn9SzSoFn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "42f54470-7d69-4929-ff66-e9f38a3d9ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/2\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f3f41554de37>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtensorboard_callback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorBoard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlog_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistogram_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m resnet_history = resnet_model.fit(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1050, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1006, in _validate_target_and_loss\n        raise ValueError(\n\n    ValueError: Target data is missing. Your model was compiled with loss=<class 'keras.losses.SparseCategoricalCrossentropy'>, and therefore expects target data to be provided in `fit()`.\n"
          ]
        }
      ],
      "source": [
        "# training the neural network with early callback for prevention of over/undertraining (given room of 50 epochs)\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
        "resnet_history = resnet_model.fit(\n",
        "    train_ds,\n",
        "    validation_data=val_ds,\n",
        "    epochs=2,\n",
        "    callbacks=[callback, tensorboard_callback]\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# precision = resnet_model.evaluate(val_ds)[1]\n",
        "# print(f\"Precision after epoch {epoch+1}: {precision}\")"
      ],
      "metadata": {
        "id": "dV8hHeMYarID"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TensorBoard Analysis"
      ],
      "metadata": {
        "id": "mckjhu-gnMxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorboard --logdir logs/fit"
      ],
      "metadata": {
        "id": "8GXCMPm0l1RU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prediction"
      ],
      "metadata": {
        "id": "YHkGsDNVyeNC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjyWDkCozxTn"
      },
      "outputs": [],
      "source": [
        "print(len(resnet_history.history['loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rkIb-0bzxTn"
      },
      "outputs": [],
      "source": [
        "# resnet_model = keras.models.load_model('/Users/manavgurnani21/Downloads/Trained_Models/Experiment_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4-bmNNnyqeZ"
      },
      "outputs": [],
      "source": [
        "# running predictions through the test dataset\n",
        "\n",
        "pred=resnet_history.model.predict(test_ds)\n",
        "print(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EeZbnghpzxTn"
      },
      "outputs": [],
      "source": [
        "# plotting the training progress of the model\n",
        "\n",
        "fig1 = plt.gcf()\n",
        "plt.plot(resnet_history.history['accuracy'])\n",
        "plt.axis(ymin=0,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZAi_ibGazxTn"
      },
      "outputs": [],
      "source": [
        "# calculating the accuracy of the model by comparing the model's labels with the actual labels\n",
        "\n",
        "import numpy as np\n",
        "pred_np = np.array(pred)\n",
        "\n",
        "correctPred = 0\n",
        "pred_np = np.asarray(pred)\n",
        "correct = np.concatenate([y for x, y in test_ds], axis=0)\n",
        "\n",
        "i = 0\n",
        "for prediction in pred_np:\n",
        "  if(np.argmax(pred_np[i]) == correct[i]):\n",
        "        correctPred += 1\n",
        "  i += 1\n",
        "\n",
        "print(correctPred)\n",
        "accuracy = correctPred / len(all_image_path_test_labels)\n",
        "\n",
        "print(\"The accuracy of this model is:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicted_classes = np.argmax(pred, axis=1)\n",
        "\n",
        "# cm = confusion_matrix(class_names, predicted_classes)\n",
        "\n",
        "# print(cm)"
      ],
      "metadata": {
        "id": "76PCTUr9sQAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8wsZUHD0zxTn"
      },
      "outputs": [],
      "source": [
        "from keras.models import save_model\n",
        "\n",
        "# keras.models.save_model(resnet_model,'/Users/manavgurnani21/Downloads/Experiment_0_1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras.models.load_model('/Users/manavgurnani21/Downloads/Experiment_0_1')"
      ],
      "metadata": {
        "id": "D1aRrtk05RTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAUH9_HuzxTo"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FSl-f8ytzxTo"
      },
      "outputs": [],
      "source": [
        "# import required module\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def applyTransformation(directory):\n",
        "    # iterate over files in\n",
        "    # that directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if(filename.__contains__('.DS_Store') == False):\n",
        "                img2 = cv2.imread(os.path.join(root, filename))\n",
        "                new = specification(os.path.join(root, filename))\n",
        "                new_2 = histogram_equalization(new)\n",
        "                new_3 = log_inverse(new_2)\n",
        "                new_4 = gamma(new_3, 0.25)\n",
        "                cv2.imwrite(os.path.join(root, filename), new_4)\n",
        "\n",
        "applyTransformation('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9cEt6ANzxTo"
      },
      "source": [
        "## Experiment 1: Hist. Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "haAJTVsdzxTo"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf\n",
        "    cdf_b = np.cumsum(h_b)\n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "\n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values\n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "\n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "\n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c80b5wOzxTo"
      },
      "source": [
        "## Experiment 2: Logarithm and Inverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cfid6BIIzxTo"
      },
      "outputs": [],
      "source": [
        "def log_inverse(image):\n",
        "    c = 255 / np.log(1 + np.max(image))\n",
        "    log_image = c * (np.log(image + 1))\n",
        "\n",
        "    # Specify the data type so that\n",
        "    # float value will be converted to int\n",
        "    log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "    img = cv2.cvtColor(log_image, cv2.COLOR_BGR2RGB)\n",
        "    colored_negative = abs(255-img)\n",
        "    return colored_negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlTvZQVnzxTo"
      },
      "source": [
        "## Experiment 3: Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1E-EoWczxTo"
      },
      "outputs": [],
      "source": [
        "def gamma(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        "\n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        "\n",
        "    return cv2.LUT(src, table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWbvnUrLzxTo"
      },
      "source": [
        "## Experiment 4: Specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONl9ErjtzxTo"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from PIL import Image\n",
        "\n",
        "def specification(path):\n",
        "    reference_unsized = cv2.cvtColor(cv2.imread('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/Colour-Wheel-Rainbow-Spectrum-Color-Wheel-1740381.jpg'), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    reference = cv2.resize(reference_unsized, (image.shape[1], image.shape[0]))\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj5YNyOnf6X"
      },
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb",
        "5k8dcy2-zxTm",
        "mckjhu-gnMxS",
        "YHkGsDNVyeNC",
        "DAUH9_HuzxTo"
      ],
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7dd6fc5c128be82ef760667744b68c23ef537939cb516a15f2e77205952262b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}