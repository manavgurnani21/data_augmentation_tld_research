{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuEeyqzznnZm"
      },
      "source": [
        "# Adding Images to Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -q kaggle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m files\u001b[39m.\u001b[39mupload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mmkdir ~/.kaggle\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      },
      "source": [
        "## Getting Day Sequence Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEDG2AtYhNL",
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ],
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      },
      "source": [
        "## Getting Clip Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "outputs": [],
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GziBHlH4g5"
      },
      "source": [
        "# Adding All Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdQUObMsW-Q"
      },
      "source": [
        "## Getting all Sequence Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrV_68rxug_v"
      },
      "source": [
        "## Getting all Clip Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "outputs": [],
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2KCYipPzis"
      },
      "source": [
        "# Sorting All Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKRu9hLzs1V"
      },
      "source": [
        "# Cropping the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "outputs": [],
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDgT7CPTUYb"
      },
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "664d2a46-7d2f-4d4e-c070-ba54183427ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "outputs": [],
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# folder = '/content/cropped_images_randomized/'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7P7n0GRQQG"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are several ways you can enhance your image detection model:\n",
        "\n",
        "# Use a more powerful model architecture: There are many different model architectures that can be used for image detection, such as VGG, ResNet, and Inception. Using a more powerful architecture can help your model learn more discriminative features and improve performance.\n",
        "\n",
        "# Fine-tune a pre-trained model: Pre-trained models have already been trained on a large dataset and can be fine-tuned for your specific task. Fine-tuning can help your model learn task-specific features and improve performance.\n",
        "\n",
        "# Use transfer learning: Transfer learning involves using the features learned by a pre-trained model and applying them to a new task. This can be an effective way to improve performance on a new task, particularly if you have a limited amount of training data.\n",
        "\n",
        "# Experiment with different hyperparameters: Hyperparameters are settings that determine the model's behavior and performance. You can try tuning different hyperparameters, such as the learning rate, batch size, and optimization algorithm, to see if they have an impact on your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "bZ9Oa5OgU1xk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/go', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/.DS_Store', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/stopLeft', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/warningLeft', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/goForward', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/stop', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/warning', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/goLeft']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + '/' + folder)\n",
        "  return pathList\n",
        "\n",
        "print(listPaths('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwcfMd8aFeJg",
        "outputId": "bfdac321-5442-4e5d-8c58-1a1245f7f5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/val'\n",
        " \n",
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size=32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulhOh93SA-C",
        "outputId": "d44667c4-27d4-45bb-a93a-0202de3c84f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B998lB9ZSRpr",
        "outputId": "d9db8cb4-88e5-4500-e7d9-67b997dd7fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-09 09:39:58.816755: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        }
      ],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVEo5KVSTr4",
        "outputId": "343e7acf-2eb2-4868-c6d4-4d4a82bbda15"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Exception encountered when calling layer \"keras_layer_2\" (type KerasLayer).\n\nin user code:\n\n    File \"/Users/manavgurnani21/anaconda3/lib/python3.9/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (4 total):\n        * <tf.Tensor 'inputs:0' shape=(None, 180, 180, 3) dtype=float32>\n        * False\n        * False\n        * 0.99\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * True\n        * False\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * True\n        * True\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * False\n        * True\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * False\n        * False\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer_2\" (type KerasLayer):\n  • inputs=tf.Tensor(shape=(None, 180, 180, 3), dtype=float32)\n  • training=False",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb Cell 38\u001b[0m in \u001b[0;36m<cell line: 30>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X52sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m mobile_net_layers \u001b[39m=\u001b[39m hub\u001b[39m.\u001b[39mKerasLayer(mobilenet_v2, input_shape\u001b[39m=\u001b[39m(\u001b[39m180\u001b[39m,\u001b[39m180\u001b[39m,\u001b[39m3\u001b[39m))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X52sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m mobile_net_layers\u001b[39m.\u001b[39mtrainable \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X52sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m neural_net \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mSequential([mobile_net_layers, tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDropout(\u001b[39m0.3\u001b[39;49m), tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mDense(\u001b[39m7\u001b[39;49m,activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msoftmax\u001b[39;49m\u001b[39m'\u001b[39;49m)])\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/trackable/base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/__autograph_generated_filesw0j0941.py:74\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     72\u001b[0m     result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope))), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     73\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mnot_(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m_has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m), \u001b[39m1\u001b[39m)\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_6\u001b[39m():\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m (result,)\n",
            "File \u001b[0;32m/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/__autograph_generated_filesw0j0941.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(smart_cond)\u001b[39m.\u001b[39;49msmart_cond, (ag__\u001b[39m.\u001b[39;49mld(training), ag__\u001b[39m.\u001b[39;49mautograph_artifact(\u001b[39mlambda\u001b[39;49;00m : ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope)), ag__\u001b[39m.\u001b[39;49mautograph_artifact(\u001b[39mlambda\u001b[39;49;00m : ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), fscope))), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
            "File \u001b[0;32m/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/__autograph_generated_filesw0j0941.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m : ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope))), \u001b[39mNone\u001b[39;00m, fscope)\n",
            "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer_2\" (type KerasLayer).\n\nin user code:\n\n    File \"/Users/manavgurnani21/anaconda3/lib/python3.9/site-packages/tensorflow_hub/keras_layer.py\", line 237, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (4 total):\n        * <tf.Tensor 'inputs:0' shape=(None, 180, 180, 3) dtype=float32>\n        * False\n        * False\n        * 0.99\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * True\n        * False\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * True\n        * True\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * False\n        * True\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (4 total):\n        * TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='inputs')\n        * False\n        * False\n        * TensorSpec(shape=(), dtype=tf.float32, name='batch_norm_momentum')\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer_2\" (type KerasLayer):\n  • inputs=tf.Tensor(shape=(None, 180, 180, 3), dtype=float32)\n  • training=False"
          ]
        }
      ],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# resnet_model = Sequential()\n",
        "\n",
        "# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "#                    input_shape=(180,180,3),\n",
        "#                    pooling='avg',classes=7,\n",
        "#                    weights='imagenet')\n",
        "# for layer in pretrained_model.layers:\n",
        "#         layer.trainable=False\n",
        "\n",
        "# resnet_model.add(pretrained_model)\n",
        "# resnet_model.add(Flatten())\n",
        "# resnet_model.add(Dense(512, activation='relu'))\n",
        "# resnet_model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "mobile_net_layers = hub.KerasLayer(mobilenet_v2, input_shape=(224,224,3))\n",
        "mobile_net_layers.trainable = False\n",
        "neural_net = tf.keras.Sequential([mobile_net_layers, tf.keras.layers.Dropout(0.3), tf.keras.layers.Dense(7,activation='softmax')])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiEFPD6-Sfgc",
        "outputId": "f3d089d0-5357-4d81-e050-1cba1bae7198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer_1 (KerasLayer)  (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 1280)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,266,951\n",
            "Trainable params: 8,967\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "neural_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "outputs": [],
      "source": [
        "# vgg_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "neural_net.compile(optimizer='Adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "moEFn9SzSoFn",
        "outputId": "870fc6df-3c16-4c3b-ec86-249614b7e896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/manavgurnani21/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb Cell 41\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m vgg_history \u001b[39m=\u001b[39m neural_net\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   train_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[callback]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X55sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "vgg_history = neural_net.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10,\n",
        "  callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'vgg_history' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb Cell 42\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/GitHub/data_augmentation_tld_research/Preprocessing.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(vgg_history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m]))\n",
            "\u001b[0;31mNameError\u001b[0m: name 'vgg_history' is not defined"
          ]
        }
      ],
      "source": [
        "print(len(vgg_history.history['loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resnet_model = keras.models.load_model('/Users/manavgurnani21/Downloads/Trained_Models/Experiment_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4-bmNNnyqeZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 107s 663ms/step\n",
            "[9.2704523e-01 1.2880091e-04 2.0646595e-04 5.2150510e-02 1.9050770e-02\n",
            " 1.4167047e-03 1.5739593e-06]\n"
          ]
        }
      ],
      "source": [
        "pred=vgg_model.predict(test_ds)\n",
        "print(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(vgg_history.history['accuracy'])\n",
        "plt.plot(vgg_history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5096\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "all_image_path_test = []\n",
        "\n",
        "for folder in listPaths('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test'):\n",
        "    if folder != '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/.DS_Store':\n",
        "        for file in listPaths(folder):\n",
        "            all_image_path_test.append(file.split('/')[-2])\n",
        "\n",
        "print(len(all_image_path_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of this model is: 0.34203296703296704\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "pred_np = np.asarray(pred)\n",
        "\n",
        "i = 0\n",
        "correct = 0\n",
        "for image_output in pred_np:\n",
        "    predicted_class_name = class_names[np.argmax(image_output)]\n",
        "    if(predicted_class_name == all_image_path_test[i]):\n",
        "        correct += 1\n",
        "    i += 1\n",
        "\n",
        "accuracy = correct / len(all_image_path_test)\n",
        "\n",
        "print(\"The accuracy of this model is:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras.models import save_model\n",
        "\n",
        "# keras.models.save_model(resnet_model,'/Users/manavgurnani21/Downloads/Trained_Models/Experiment_16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj5YNyOnf6X"
      },
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_6612/1493919654.py:12: FutureWarning: `multichannel` is a deprecated argument name for `match_histograms`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  matched = match_histograms(image, reference, multichannel=True)\n",
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_6612/1285761232.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  log_image = c * (np.log(image + 1))\n"
          ]
        }
      ],
      "source": [
        "# import required module\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def applyTransformation(directory):\n",
        "    # iterate over files in\n",
        "    # that directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if(filename.__contains__('.DS_Store') == False):\n",
        "                img2 = cv2.imread(os.path.join(root, filename))\n",
        "                new = specification(os.path.join(root, filename))\n",
        "                new_2 = histogram_equalization(new)\n",
        "                new_3 = log_inverse(new_2)\n",
        "                new_4 = gamma(new_3, 0.25)\n",
        "                cv2.imwrite(os.path.join(root, filename), new_4)\n",
        "\n",
        "applyTransformation('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1: Hist. Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2: Logarithm and Inverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_inverse(image):\n",
        "    c = 255 / np.log(1 + np.max(image))\n",
        "    log_image = c * (np.log(image + 1))\n",
        "    \n",
        "    # Specify the data type so that\n",
        "    # float value will be converted to int\n",
        "    log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "    img = cv2.cvtColor(log_image, cv2.COLOR_BGR2RGB)\n",
        "    colored_negative = abs(255-img)\n",
        "    return colored_negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3: Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gamma(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        "\n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        "\n",
        "    return cv2.LUT(src, table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4: Specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from PIL import Image\n",
        "\n",
        "def specification(path):\n",
        "    reference_unsized = cv2.cvtColor(cv2.imread('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/Colour-Wheel-Rainbow-Spectrum-Color-Wheel-1740381.jpg'), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    reference = cv2.resize(reference_unsized, (image.shape[1], image.shape[0]))\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "MdOUu5ltoUJ2",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7dd6fc5c128be82ef760667744b68c23ef537939cb516a15f2e77205952262b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
