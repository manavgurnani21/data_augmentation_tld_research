{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "MdOUu5ltoUJ2",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Images to Drive Folder"
      ],
      "metadata": {
        "id": "RuEeyqzznnZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ],
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Day Sequence Paths"
      ],
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ],
      "metadata": {
        "id": "uGEDG2AtYhNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Clip Paths"
      ],
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ],
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding All Annotations"
      ],
      "metadata": {
        "id": "W_GziBHlH4g5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all Sequence Annotations"
      ],
      "metadata": {
        "id": "XRdQUObMsW-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ],
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ],
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all Clip Annotations"
      ],
      "metadata": {
        "id": "wrV_68rxug_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ],
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting All Lists"
      ],
      "metadata": {
        "id": "be2KCYipPzis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ],
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cropping the Images"
      ],
      "metadata": {
        "id": "ESKRu9hLzs1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ],
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ],
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ],
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ],
      "metadata": {
        "id": "LYDgT7CPTUYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "664d2a46-7d2f-4d4e-c070-ba54183427ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ],
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# def listPaths(path):\n",
        "#   pathList = []\n",
        "#   for folder in os.listdir(path):\n",
        "#     if folder == '.ipynb_checkpoints':\n",
        "#       continue\n",
        "#     pathList.append(path + folder + '/')\n",
        "#     random.shuffle(pathList)\n",
        "#   return pathList\n",
        "\n",
        "# print(listPaths('/content/content/allCroppedImages/'))"
      ],
      "metadata": {
        "id": "bZ9Oa5OgU1xk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ],
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ],
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ],
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import os, shutil\n",
        "# folder = '/content/cropped_images_randomized/'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ],
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset"
      ],
      "metadata": {
        "id": "ED7P7n0GRQQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/content/cropped_images_randomized/val'\n",
        " \n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size=32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xwcfMd8aFeJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdac321-5442-4e5d-8c58-1a1245f7f5e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "iulhOh93SA-C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44667c4-27d4-45bb-a93a-0202de3c84f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "B998lB9ZSRpr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9db8cb4-88e5-4500-e7d9-67b997dd7fbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=7,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(7, activation='softmax'))"
      ],
      "metadata": {
        "id": "7sVEo5KVSTr4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343e7acf-2eb2-4868-c6d4-4d4a82bbda15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94765736/94765736 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "BiEFPD6-Sfgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d089d0-5357-4d81-e050-1cba1bae7198"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " module_wrapper (ModuleWrapp  (None, 2048)             0         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " module_wrapper_1 (ModuleWra  (None, 512)              1049088   \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_2 (ModuleWra  (None, 7)                3591      \n",
            " pper)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,640,391\n",
            "Trainable params: 1,052,679\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model_ever.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=15, verbose=1, mode='auto')\n",
        "resnet_history = resnet_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  callbacks=[early, checkpoint],\n",
        "  epochs=1\n",
        ")\n",
        "\n",
        "fig1 = plt.gcf()\n",
        "plt.plot(resnet_history.history['accuracy'])\n",
        "plt.plot(resnet_history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "moEFn9SzSoFn",
        "outputId": "870fc6df-3c16-4c3b-ec86-249614b7e896"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1274/1274 [==============================] - ETA: 0s - loss: 0.1294 - accuracy: 0.9552"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,val_loss,val_accuracy\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1274/1274 [==============================] - 4550s 4s/step - loss: 0.1294 - accuracy: 0.9552 - val_loss: 0.0913 - val_accuracy: 0.9684\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pred=resnet_model.predict('/content')\n",
        "# print(pred)"
      ],
      "metadata": {
        "id": "U4-bmNNnyqeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ],
      "metadata": {
        "id": "ljj5YNyOnf6X"
      }
    }
  ]
}