{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuEeyqzznnZm"
      },
      "source": [
        "# Adding Images to Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -q kaggle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m files\u001b[39m.\u001b[39mupload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mmkdir ~/.kaggle\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      },
      "source": [
        "## Getting Day Sequence Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEDG2AtYhNL",
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ],
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      },
      "source": [
        "## Getting Clip Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "outputs": [],
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GziBHlH4g5"
      },
      "source": [
        "# Adding All Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdQUObMsW-Q"
      },
      "source": [
        "## Getting all Sequence Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrV_68rxug_v"
      },
      "source": [
        "## Getting all Clip Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "outputs": [],
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2KCYipPzis"
      },
      "source": [
        "# Sorting All Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKRu9hLzs1V"
      },
      "source": [
        "# Cropping the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "outputs": [],
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDgT7CPTUYb"
      },
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "664d2a46-7d2f-4d4e-c070-ba54183427ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "outputs": [],
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# folder = '/content/cropped_images_randomized/'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7P7n0GRQQG"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "bZ9Oa5OgU1xk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/go', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/stopLeft', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/warningLeft', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/goForward', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/stop', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/warning', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/goLeft']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + '/' + folder)\n",
        "  return pathList\n",
        "\n",
        "print(listPaths('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwcfMd8aFeJg",
        "outputId": "bfdac321-5442-4e5d-8c58-1a1245f7f5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/val'\n",
        " \n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size=32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulhOh93SA-C",
        "outputId": "d44667c4-27d4-45bb-a93a-0202de3c84f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B998lB9ZSRpr",
        "outputId": "d9db8cb4-88e5-4500-e7d9-67b997dd7fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ]
        }
      ],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVEo5KVSTr4",
        "outputId": "343e7acf-2eb2-4868-c6d4-4d4a82bbda15"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=7,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiEFPD6-Sfgc",
        "outputId": "f3d089d0-5357-4d81-e050-1cba1bae7198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " module_wrapper_6 (ModuleWra  (None, 2048)             0         \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_7 (ModuleWra  (None, 512)              1049088   \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_8 (ModuleWra  (None, 7)                3591      \n",
            " pper)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,640,391\n",
            "Trainable params: 1,052,679\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "outputs": [],
      "source": [
        "resnet_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "moEFn9SzSoFn",
        "outputId": "870fc6df-3c16-4c3b-ec86-249614b7e896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/manavgurnani21/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1274/1274 [==============================] - 1351s 1s/step - loss: 0.2258 - accuracy: 0.9245 - val_loss: 0.4258 - val_accuracy: 0.8843\n",
            "Epoch 2/10\n",
            "1261/1274 [============================>.] - ETA: 23s - loss: 0.1126 - accuracy: 0.9583"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb Cell 40\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m callback \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mcallbacks\u001b[39m.\u001b[39mEarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m resnet_history \u001b[39m=\u001b[39m resnet_model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   train_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m   epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m   callbacks\u001b[39m=\u001b[39;49m[callback]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#X54sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "resnet_history = resnet_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10,\n",
        "  callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(resnet_history.history['loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(resnet_history.history['accuracy'])\n",
        "plt.plot(resnet_history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U4-bmNNnyqeZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 116s 725ms/step\n",
            "[9.9999452e-01 5.4226901e-15 3.1210215e-07 8.6100636e-07 1.5409550e-14\n",
            " 4.2210445e-06 4.7442274e-08]\n"
          ]
        }
      ],
      "source": [
        "pred=resnet_model.predict(test_ds)\n",
        "print(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5096\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "all_image_path_test = []\n",
        "\n",
        "for folder in listPaths('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test'):\n",
        "    for file in listPaths(folder):\n",
        "        all_image_path_test.append(file.split('/')[-2])\n",
        "\n",
        "print(len(all_image_path_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of this model is: 0.3031789638932496\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "pred_np = np.asarray(pred)\n",
        "\n",
        "i = 0\n",
        "correct = 0\n",
        "for image_output in pred_np:\n",
        "    predicted_class_name = class_names[np.argmax(image_output)]\n",
        "    if(predicted_class_name == all_image_path_test[i]):\n",
        "        correct += 1\n",
        "    i += 1\n",
        "\n",
        "accuracy = correct / len(all_image_path_test)\n",
        "\n",
        "print(\"The accuracy of this model is:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/manavgurnani21/Downloads/Trained_Models/Experiment_4/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/manavgurnani21/Downloads/Trained_Models/Experiment_4/assets\n"
          ]
        }
      ],
      "source": [
        "# from keras.models import save_model\n",
        "\n",
        "# keras.models.save_model(resnet_model,'/Users/manavgurnani21/Downloads/Trained_Models/Experiment_4')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj5YNyOnf6X"
      },
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import required module\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def applyTransformation(directory):\n",
        "    # iterate over files in\n",
        "    # that directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if(filename.__contains__('.DS_Store') == False):\n",
        "                img2 = cv2.imread(os.path.join(root, filename))\n",
        "                new = histogram_equalization(img2)\n",
        "                new_final = gamma(new, 0.25)\n",
        "                cv2.imwrite(os.path.join(root, filename), new_final)\n",
        "\n",
        "applyTransformation('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1: Hist. Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2: Logarithm and Inverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_inverse(image):\n",
        "    c = 255 / np.log(1 + np.max(image))\n",
        "    log_image = c * (np.log(image + 1))\n",
        "    \n",
        "    # Specify the data type so that\n",
        "    # float value will be converted to int\n",
        "    log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "    img = cv2.cvtColor(log_image, cv2.COLOR_BGR2RGB)\n",
        "    colored_negative = abs(255-img)\n",
        "    return colored_negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3: Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gamma(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        "\n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        "\n",
        "    return cv2.LUT(src, table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4: Specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from PIL import Image\n",
        "\n",
        "def specification(path):\n",
        "    reference_unsized = cv2.cvtColor(cv2.imread('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/Colour-Wheel-Rainbow-Spectrum-Color-Wheel-1740381.jpg'), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    reference = cv2.resize(reference_unsized, (image.shape[1], image.shape[0]))\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "MdOUu5ltoUJ2",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7dd6fc5c128be82ef760667744b68c23ef537939cb516a15f2e77205952262b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
