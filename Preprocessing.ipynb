{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "MdOUu5ltoUJ2",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "be2KCYipPzis"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding Images to Drive Folder"
      ],
      "metadata": {
        "id": "RuEeyqzznnZm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ],
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Day Sequence Paths"
      ],
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ],
      "metadata": {
        "id": "uGEDG2AtYhNL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting Clip Paths"
      ],
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ],
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Adding All Annotations"
      ],
      "metadata": {
        "id": "W_GziBHlH4g5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all Sequence Annotations"
      ],
      "metadata": {
        "id": "XRdQUObMsW-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ],
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ],
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Getting all Clip Annotations"
      ],
      "metadata": {
        "id": "wrV_68rxug_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ],
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sorting All Lists"
      ],
      "metadata": {
        "id": "be2KCYipPzis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ],
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cropping the Images"
      ],
      "metadata": {
        "id": "ESKRu9hLzs1V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ],
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ],
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ],
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ],
      "metadata": {
        "id": "LYDgT7CPTUYb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "087ac254-d4bf-4098-89f7-cde008adbdba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/drive/MyDrive/allCroppedImages/allCroppedImages.zip' -d '/content/'"
      ],
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.mkdir('/content/train/')\n",
        "os.mkdir('/content/test/')\n",
        "os.mkdir('/content/val/')\n",
        "\n",
        "folderList = ['train', 'test', 'val']\n",
        "for name in folderList:\n",
        "  os.mkdir('/content/' + name + '/stop/')\n",
        "  os.mkdir('/content/' + name + '/go/')\n",
        "  os.mkdir('/content/' + name + '/warning/')\n",
        "  os.mkdir('/content/' + name + '/warningLeft/')\n",
        "  os.mkdir('/content/' + name + '/goLeft/')\n",
        "  os.mkdir('/content/' + name + '/stopLeft/')\n",
        "  os.mkdir('/content/' + name + '/goForward/')"
      ],
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + folder + '/')\n",
        "    random.shuffle(pathList)\n",
        "  return pathList\n",
        "\n",
        "print(listPaths('/content/content/allCroppedImages/'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ9Oa5OgU1xk",
        "outputId": "676f3f89-e1c3-4026-c69c-11452f6289df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['/content/content/allCroppedImages/warning/', '/content/content/allCroppedImages/stop/', '/content/content/allCroppedImages/goForward/', '/content/content/allCroppedImages/go/', '/content/content/allCroppedImages/goLeft/', '/content/content/allCroppedImages/warningLeft/', '/content/content/allCroppedImages/stopLeft/']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import shutil\n",
        "\n",
        "def shuffleSelection(path):\n",
        "  allFolders = listPaths(path)\n",
        "  for folder in allFolders:\n",
        "    df = pd.DataFrame(listPaths(folder))\n",
        "    trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "    moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "  finalTrainPathList = np.asarray(trainPaths[0])\n",
        "  type(finalTrainPathList)\n",
        "  finalTestPathList = np.asarray(testPaths[0])\n",
        "  finalValPathList = np.asarray(valPaths[0])\n",
        "  for path in finalTrainPathList:\n",
        "    shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "  for path in finalTestPathList:\n",
        "    shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "  for path in finalValPathList:\n",
        "    shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ],
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shuffleSelection('/content/content/allCroppedImages/')"
      ],
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, shutil\n",
        "folder = '/content/sample-nightClip1/'\n",
        "for filename in os.listdir(folder):\n",
        "    file_path = os.path.join(folder, filename)\n",
        "    try:\n",
        "        if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "            os.unlink(file_path)\n",
        "        elif os.path.isdir(file_path):\n",
        "            shutil.rmtree(file_path)\n",
        "    except Exception as e:\n",
        "        print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ],
      "metadata": {
        "id": "Y_PgaU3VE4qW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Dataset"
      ],
      "metadata": {
        "id": "ED7P7n0GRQQG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/content/train/'\n",
        "test_data_dir = '/content/test/'\n",
        "val_data_dir = '/content/val/'\n",
        " \n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size=32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "metadata": {
        "id": "xwcfMd8aFeJg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf86153-3bd3-4554-81bd-3ddc58a4e974"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "id": "iulhOh93SA-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ],
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "metadata": {
        "id": "B998lB9ZSRpr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=5,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "7sVEo5KVSTr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.summary()"
      ],
      "metadata": {
        "id": "BiEFPD6-Sfgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "checkpoint = ModelCheckpoint(\"best_model_ever.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "history = resnet_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  callbacks=[early, checkpoint],\n",
        "  epochs=10\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "moEFn9SzSoFn",
        "outputId": "caf8bcd7-4f54-442a-df9e-51a0164c28d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "   1/1274 [..............................] - ETA: 1:00:51 - loss: 1.2707 - accuracy: 0.7500"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-25ca6bd5b07c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearly\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 612, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/ioloop.py\", line 758, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1233, in inner\n      self.run()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 1147, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 365, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 268, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 545, in execute_request\n      user_expressions, allow_stdin,\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/gen.py\", line 326, in wrapper\n      yielded = next(result)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 306, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2855, in run_cell\n      raw_cell, store_history, silent, shell_futures)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2881, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/async_helpers.py\", line 68, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3058, in run_cell_async\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3249, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 3326, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-34-45a1f6f556e9>\", line 10, in <module>\n      epochs=epochs\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1409, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1051, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1040, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1030, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 890, in train_step\n      loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 949, in compute_loss\n      y, y_pred, sample_weight, regularization_losses=self.losses)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/compile_utils.py\", line 201, in __call__\n      loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 139, in __call__\n      losses = call_fn(y_true, y_pred)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 243, in call\n      return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/losses.py\", line 1861, in sparse_categorical_crossentropy\n      y_true, y_pred, from_logits=from_logits, axis=axis)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/backend.py\", line 5239, in sparse_categorical_crossentropy\n      labels=target, logits=output)\nNode: 'sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits'\nReceived a label value of 5 which is outside the valid range of [0, 5).  Label values: 3 0 3 0 3 4 4 2 3 3 0 3 5 3 3 3 0 2 4 0 3 0 4 4 3 0 3 3 3 3 3 0\n\t [[{{node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]] [Op:__inference_train_function_9923]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ],
      "metadata": {
        "id": "ljj5YNyOnf6X"
      }
    }
  ]
}