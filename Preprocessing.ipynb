{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuEeyqzznnZm"
      },
      "source": [
        "# Adding Images to Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -q kaggle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m files\u001b[39m.\u001b[39mupload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mmkdir ~/.kaggle\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      },
      "source": [
        "## Getting Day Sequence Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEDG2AtYhNL",
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ],
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      },
      "source": [
        "## Getting Clip Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "outputs": [],
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GziBHlH4g5"
      },
      "source": [
        "# Adding All Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdQUObMsW-Q"
      },
      "source": [
        "## Getting all Sequence Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrV_68rxug_v"
      },
      "source": [
        "## Getting all Clip Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "outputs": [],
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2KCYipPzis"
      },
      "source": [
        "# Sorting All Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKRu9hLzs1V"
      },
      "source": [
        "# Cropping the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "outputs": [],
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDgT7CPTUYb"
      },
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "664d2a46-7d2f-4d4e-c070-ba54183427ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bZ9Oa5OgU1xk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/go', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/stopLeft', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/warningLeft', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/goForward', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/stop', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/warning', '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test/goLeft']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + '/' + folder)\n",
        "  return pathList\n",
        "\n",
        "print(listPaths('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "outputs": [],
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# folder = '/content/cropped_images_randomized/'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7P7n0GRQQG"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwcfMd8aFeJg",
        "outputId": "bfdac321-5442-4e5d-8c58-1a1245f7f5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/val'\n",
        " \n",
        "img_height = 180\n",
        "img_width = 180\n",
        "batch_size=32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulhOh93SA-C",
        "outputId": "d44667c4-27d4-45bb-a93a-0202de3c84f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B998lB9ZSRpr",
        "outputId": "d9db8cb4-88e5-4500-e7d9-67b997dd7fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2022-11-08 00:47:59.526728: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        }
      ],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVEo5KVSTr4",
        "outputId": "343e7acf-2eb2-4868-c6d4-4d4a82bbda15"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "resnet_model = Sequential()\n",
        "\n",
        "pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "                   input_shape=(180,180,3),\n",
        "                   pooling='avg',classes=7,\n",
        "                   weights='imagenet')\n",
        "for layer in pretrained_model.layers:\n",
        "        layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(512, activation='relu'))\n",
        "resnet_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiEFPD6-Sfgc",
        "outputId": "f3d089d0-5357-4d81-e050-1cba1bae7198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " resnet50 (Functional)       (None, 2048)              23587712  \n",
            "                                                                 \n",
            " module_wrapper (ModuleWrapp  (None, 2048)             0         \n",
            " er)                                                             \n",
            "                                                                 \n",
            " module_wrapper_1 (ModuleWra  (None, 512)              1049088   \n",
            " pper)                                                           \n",
            "                                                                 \n",
            " module_wrapper_2 (ModuleWra  (None, 7)                3591      \n",
            " pper)                                                           \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 24,640,391\n",
            "Trainable params: 1,052,679\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "resnet_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "outputs": [],
      "source": [
        "resnet_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "moEFn9SzSoFn",
        "outputId": "870fc6df-3c16-4c3b-ec86-249614b7e896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/manavgurnani21/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1274/1274 [==============================] - 972s 762ms/step - loss: 0.1318 - accuracy: 0.9543 - val_loss: 0.0747 - val_accuracy: 0.9712\n",
            "Epoch 2/10\n",
            "1274/1274 [==============================] - 966s 759ms/step - loss: 0.0631 - accuracy: 0.9765 - val_loss: 0.0581 - val_accuracy: 0.9804\n",
            "Epoch 3/10\n",
            "1274/1274 [==============================] - 963s 756ms/step - loss: 0.0492 - accuracy: 0.9820 - val_loss: 0.0542 - val_accuracy: 0.9808\n",
            "Epoch 4/10\n",
            "1274/1274 [==============================] - 948s 744ms/step - loss: 0.0387 - accuracy: 0.9857 - val_loss: 0.0672 - val_accuracy: 0.9778\n",
            "Epoch 5/10\n",
            "1274/1274 [==============================] - 948s 744ms/step - loss: 0.0323 - accuracy: 0.9881 - val_loss: 0.1210 - val_accuracy: 0.9667\n",
            "Epoch 6/10\n",
            "1274/1274 [==============================] - 946s 742ms/step - loss: 0.0278 - accuracy: 0.9899 - val_loss: 0.0870 - val_accuracy: 0.9770\n",
            "Epoch 7/10\n",
            "1274/1274 [==============================] - 945s 742ms/step - loss: 0.0247 - accuracy: 0.9909 - val_loss: 0.0439 - val_accuracy: 0.9865\n",
            "Epoch 8/10\n",
            "1274/1274 [==============================] - 947s 743ms/step - loss: 0.0209 - accuracy: 0.9924 - val_loss: 0.0648 - val_accuracy: 0.9829\n",
            "Epoch 9/10\n",
            "1274/1274 [==============================] - 949s 745ms/step - loss: 0.0197 - accuracy: 0.9928 - val_loss: 0.0443 - val_accuracy: 0.9863\n",
            "Epoch 10/10\n",
            "1274/1274 [==============================] - 945s 742ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.0664 - val_accuracy: 0.9823\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
        "\n",
        "resnet_history = resnet_model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10,\n",
        "  callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(resnet_history.history['loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(resnet_history.history['accuracy'])\n",
        "plt.plot(resnet_history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 59). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/manavgurnani21/Downloads/Trained_Models/Experiment_0/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /Users/manavgurnani21/Downloads/Trained_Models/Experiment_0/assets\n"
          ]
        }
      ],
      "source": [
        "from keras.models import save_model\n",
        "\n",
        "keras.models.save_model(resnet_model,'/Users/manavgurnani21/Downloads/Trained_Models/Experiment_0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "U4-bmNNnyqeZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 105s 656ms/step\n",
            "[1.0000000e+00 4.2501547e-10 3.4630812e-08 1.0112776e-09 7.1065424e-11\n",
            " 8.9497514e-11 2.8333930e-12]\n"
          ]
        }
      ],
      "source": [
        "pred=resnet_model.predict(test_ds)\n",
        "print(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5096\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "all_image_path_test = []\n",
        "\n",
        "for folder in listPaths('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/test'):\n",
        "    for file in listPaths(folder):\n",
        "        all_image_path_test.append(file.split('/')[-2])\n",
        "\n",
        "print(len(all_image_path_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of this model is: 0.3161302982731554\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "pred_np = np.asarray(pred)\n",
        "\n",
        "i = 0\n",
        "correct = 0\n",
        "for image_output in pred_np:\n",
        "    predicted_class_name = class_names[np.argmax(image_output)]\n",
        "    if(predicted_class_name == all_image_path_test[i]):\n",
        "        correct += 1\n",
        "    i += 1\n",
        "\n",
        "accuracy = correct / len(all_image_path_test)\n",
        "\n",
        "print(\"The accuracy of this model is:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj5YNyOnf6X"
      },
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_442/1285761232.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  log_image = c * (np.log(image + 1))\n"
          ]
        }
      ],
      "source": [
        "# import required module\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def applyTransformation(directory):\n",
        "    # iterate over files in\n",
        "    # that directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if(filename.__contains__('.DS_Store') == False):\n",
        "                img2 = cv2.imread(os.path.join(root, filename))\n",
        "                new = histogram_equalization(img2)\n",
        "                new_final = log_inverse(new)\n",
        "                cv2.imwrite(os.path.join(root, filename), new_final)\n",
        "\n",
        "applyTransformation('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1: Hist. Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2: Logarithm and Inverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_inverse(image):\n",
        "    c = 255 / np.log(1 + np.max(image))\n",
        "    log_image = c * (np.log(image + 1))\n",
        "    \n",
        "    # Specify the data type so that\n",
        "    # float value will be converted to int\n",
        "    log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "    img = cv2.cvtColor(log_image, cv2.COLOR_BGR2RGB)\n",
        "    colored_negative = abs(255-img)\n",
        "    return colored_negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3: Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gamma(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        "\n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        "\n",
        "    return cv2.LUT(src, table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4: Specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from PIL import Image\n",
        "\n",
        "def specification(path):\n",
        "    reference_unsized = cv2.cvtColor(cv2.imread('/Users/manavgurnani21/Downloads/cropped_images_randomized/content/cropped_images_randomized/Colour-Wheel-Rainbow-Spectrum-Color-Wheel-1740381.jpg'), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    reference = cv2.resize(reference_unsized, (image.shape[1], image.shape[0]))\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "MdOUu5ltoUJ2",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7dd6fc5c128be82ef760667744b68c23ef537939cb516a15f2e77205952262b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
