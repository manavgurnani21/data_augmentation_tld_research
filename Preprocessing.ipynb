{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manavgurnani21/data_augmentation_tld_research/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuEeyqzznnZm"
      },
      "source": [
        "# Adding Images to Drive Folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mdjgiM_BXF-o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'google.colab'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mpip install -q kaggle\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m files\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m files\u001b[39m.\u001b[39mupload()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/manavgurnani21/Downloads/data_augmentation_tld_research/Preprocessing.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39msystem(\u001b[39m'\u001b[39m\u001b[39mmkdir ~/.kaggle\u001b[39m\u001b[39m'\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
          ]
        }
      ],
      "source": [
        "!pip install -q kaggle\n",
        "\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "\n",
        "!mkdir ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!kaggle datasets download -d mbornoe/lisa-traffic-light-dataset\n",
        "!unzip lisa-traffic-light-dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SX1W511hYVHr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# getting current directory\n",
        "os.getcwd()\n",
        "\n",
        "all_image_paths = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DmJJXJbh_CZ"
      },
      "source": [
        "## Getting Day Sequence Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGEDG2AtYhNL",
        "outputId": "07c629db-8896-4c07-b4f0-ffa875e63170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['content', 'daySequence1', 'daySequence2', 'drive', 'nightSequence1', 'nightSequence2', 'sample-dayClip6', 'sample-nightClip1', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "# getting all paths for content layer\n",
        "content = os.listdir('/content/')\n",
        "content.sort()\n",
        "content = content[:-3]\n",
        "content.remove('.config')\n",
        "content.remove('kaggle.json')\n",
        "content.remove('lisa-traffic-light-dataset.zip')\n",
        "content.remove('Annotations')\n",
        "content.remove('dayTrain')\n",
        "content.remove('nightTrain')\n",
        "for folder in content:\n",
        "  if folder == '.ipynb_checkpoints':\n",
        "    content.remove('.ipynb_checkpoints')\n",
        "print(content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "bF2_X1ZQf6Zy",
        "outputId": "eea744d1-cb22-4b0b-bb2a-72f9fa1eba3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/content/content/frames/\n"
          ]
        },
        {
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ed3d81765283>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_image_paths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/frames/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/content/content/frames/'"
          ]
        }
      ],
      "source": [
        "for folder in content:\n",
        "  print('/content/' + folder + '/' + folder + '/frames/')\n",
        "  list = os.listdir('/content/' + folder + '/' + folder + '/frames/')\n",
        "  for path in list:\n",
        "    all_image_paths.append('/content/' + folder + '/' + folder + '/frames/' + path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdOUu5ltoUJ2"
      },
      "source": [
        "## Getting Clip Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xpxf7Ymobyy"
      },
      "outputs": [],
      "source": [
        "train_paths = ['/content/dayTrain/dayTrain/', '/content/nightTrain/nightTrain/']\n",
        "for path in train_paths:\n",
        "  list1 = os.listdir(path)\n",
        "  if '.DS_Store' in list1:\n",
        "    list1.remove('.DS_Store')\n",
        "  for name in list1:\n",
        "    list2 = os.listdir(path + name + '/frames/')\n",
        "    for item in list2:\n",
        "      all_image_paths.append(path + name + '/frames/' + item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_GziBHlH4g5"
      },
      "source": [
        "# Adding All Annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdQUObMsW-Q"
      },
      "source": [
        "## Getting all Sequence Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPVUG9plvGgz"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "all_annotation_paths = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RKKW1rOer6py"
      },
      "outputs": [],
      "source": [
        "root_path = '/content/Annotations/Annotations'\n",
        "main = os.listdir(root_path)\n",
        "main.remove('dayTrain')\n",
        "main.remove('nightTrain')\n",
        "\n",
        "for folder in main:\n",
        "  list1 = os.listdir(root_path + '/' + folder)\n",
        "  list1[0] = folder + list1[0]\n",
        "  os.rename(root_path + folder + '/frameAnnotationsBOX.csv', root_path + folder + '/' + list1[0])\n",
        "  all_annotation_paths.append(root_path + folder + '/' + list1[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrV_68rxug_v"
      },
      "source": [
        "## Getting all Clip Annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m909lXKAukiH"
      },
      "outputs": [],
      "source": [
        "clipPaths = [root_path + 'dayTrain/', root_path + 'nightTrain/']\n",
        "\n",
        "for folder in clipPaths:\n",
        "  list2 = os.listdir(folder)\n",
        "  for name in list2:\n",
        "    list3 = os.listdir(folder + name)\n",
        "    list3[0] = name + list3[0]\n",
        "    print(folder + name + '/' + list3[0])\n",
        "    os.rename(folder + name + '/frameAnnotationsBOX.csv', folder + name + '/' + list3[0])\n",
        "    all_annotation_paths.append(folder + name + '/' + list3[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be2KCYipPzis"
      },
      "source": [
        "# Sorting All Lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wf5_HoyP5vl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "image_paths = np.asarray(all_image_paths)\n",
        "sorted_image_paths = np.sort(image_paths)\n",
        "print(sorted_image_paths)\n",
        "\n",
        "annotation_paths = np.asarray(all_annotation_paths)\n",
        "sorted_annotation_paths = np.sort(annotation_paths)\n",
        "print(sorted_annotation_paths)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESKRu9hLzs1V"
      },
      "source": [
        "# Cropping the Images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IVwmc2HkB-eG"
      },
      "outputs": [],
      "source": [
        "def findIndexofElement(value, array):\n",
        "  for i in range(len(array)):\n",
        "    if array[i][array[i].rfind('/'):] == value:\n",
        "      return i\n",
        "      break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BgCY6gHAJePn"
      },
      "outputs": [],
      "source": [
        "os.mkdir('/content/allCroppedImages/')\n",
        "os.mkdir('/content/allCroppedImages/stop/')\n",
        "os.mkdir('/content/allCroppedImages/warning/')\n",
        "os.mkdir('/content/allCroppedImages/go/')\n",
        "os.mkdir('/content/allCroppedImages/warningLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goLeft/')\n",
        "os.mkdir('/content/allCroppedImages/stopLeft/')\n",
        "os.mkdir('/content/allCroppedImages/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYR4f-Jm9Bte"
      },
      "outputs": [],
      "source": [
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from tensorflow.keras.utils import array_to_img\n",
        "from tensorflow.keras.utils import load_img\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "def cropAllImages(path):\n",
        "  df = pd.read_csv(path, sep=';')\n",
        "  filenames = df['Filename']\n",
        "  leftX = np.asarray(df['Upper left corner X'])\n",
        "  rightX = np.asarray(df['Lower right corner X'])\n",
        "  leftY = np.asarray(df['Upper left corner Y'])\n",
        "  rightY = np.asarray(df['Lower right corner Y'])\n",
        "  tag = np.asarray(df['Annotation tag'])\n",
        "\n",
        "  image_saved_counter = 0\n",
        "\n",
        "  # loc_index is the location of the image path in all sorted paths\n",
        "  for i in range(len(filenames)):\n",
        "    findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)\n",
        "    img = img_to_array(load_img(sorted_image_paths[findIndexofElement(filenames[i][filenames[i].rfind('/'):], sorted_image_paths)]))\n",
        "    crop_img = array_to_img(img[leftY[i]:rightY[i], leftX[i]:rightX[i]])\n",
        "    # inputting them in folder\n",
        "    crop_img.save('/content/allCroppedImages/' + tag[i] + filenames[i][filenames[i].rfind('/'):])\n",
        "    image_saved_counter+=1\n",
        "    if(image_saved_counter%1000==0):\n",
        "      print(image_saved_counter)\n",
        "\n",
        "# for path in all_annotation_paths:\n",
        "#   cropAllImages(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Nnl9YYrgMvZv",
        "outputId": "172ce5cc-b071-432a-a572-2f667ba96e6d"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_41dd0b06-20e3-42df-972e-3fa70175a9f0\", \"allCroppedImages.zip\", 49923220)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/\"allCroppedImages.zip\"' '/content/allCroppedImages'\n",
        "# files.download('/content/allCroppedImages.zip')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYDgT7CPTUYb"
      },
      "source": [
        "# Randomly Assigning Files\n",
        "\n",
        "- after putting into sub-folders\n",
        "- for each subfolder:\n",
        "  - put all names in a list\n",
        "  - shuffle\n",
        "  - get all three indices\n",
        "  - put into train, test, val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTjvPhm8EKyN",
        "outputId": "664d2a46-7d2f-4d4e-c070-ba54183427ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxcZOYHASmSJ"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/drive/MyDrive/cropped_images_randomized/cropped_images_randomized.zip' -d '/content/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I4w6UQUivgOT"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "\n",
        "# os.mkdir('/content/train/')\n",
        "# os.mkdir('/content/test/')\n",
        "# os.mkdir('/content/val/')\n",
        "\n",
        "# folderList = ['train', 'test', 'val']\n",
        "# for name in folderList:\n",
        "#   os.mkdir('/content/' + name + '/stop/')\n",
        "#   os.mkdir('/content/' + name + '/go/')\n",
        "#   os.mkdir('/content/' + name + '/warning/')\n",
        "#   os.mkdir('/content/' + name + '/warningLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goLeft/')\n",
        "#   os.mkdir('/content/' + name + '/stopLeft/')\n",
        "#   os.mkdir('/content/' + name + '/goForward/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y1b3zB_8WZcv"
      },
      "outputs": [],
      "source": [
        "# import random\n",
        "# import shutil\n",
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "\n",
        "# def shuffleSelection(path):\n",
        "#   allFolders = listPaths(path)\n",
        "#   for folder in allFolders:\n",
        "#     df = pd.DataFrame(listPaths(folder))\n",
        "#     trainPaths, testPaths, valPaths = np.split(df, [int(.8 * len(df)), int(.9 * len(df))])\n",
        "#     moveToFolder(trainPaths, testPaths, valPaths)\n",
        "\n",
        "# def moveToFolder(trainPaths, testPaths, valPaths):\n",
        "#   finalTrainPathList = np.asarray(trainPaths[0])\n",
        "#   type(finalTrainPathList)\n",
        "#   finalTestPathList = np.asarray(testPaths[0])\n",
        "#   finalValPathList = np.asarray(valPaths[0])\n",
        "#   for path in finalTrainPathList:\n",
        "#     shutil.move(path[:-1], '/content/train' + path[33:-1])\n",
        "#   for path in finalTestPathList:\n",
        "#     shutil.move(path[:-1], '/content/test' + path[33:-1])\n",
        "#   for path in finalValPathList:\n",
        "#     shutil.move(path[:-1], '/content/val' + path[33:-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5mxUnol_YBBC"
      },
      "outputs": [],
      "source": [
        "# shuffleSelection('/content/content/allCroppedImages/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shJJCwQ1ZeSK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# !zip -r '/content/cropped_images_randomized.zip' '/content/cropped_images_randomized'\n",
        "# files.download('/content/cropped_images_randomized.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb2Klr1_BFqT"
      },
      "outputs": [],
      "source": [
        "# import os, shutil\n",
        "# folder = '/content/cropped_images_randomized/'\n",
        "# for filename in os.listdir(folder):\n",
        "#     file_path = os.path.join(folder, filename)\n",
        "#     try:\n",
        "#         if os.path.isfile(file_path) or os.path.islink(file_path):\n",
        "#             os.unlink(file_path)\n",
        "#         elif os.path.isdir(file_path):\n",
        "#             shutil.rmtree(file_path)\n",
        "#     except Exception as e:\n",
        "#         print('Failed to delete %s. Reason: %s' % (file_path, e))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ED7P7n0GRQQG"
      },
      "source": [
        "# Training Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are several ways you can enhance your image detection model:\n",
        "\n",
        "# Use a more powerful model architecture: There are many different model architectures that can be used for image detection, such as VGG, ResNet, and Inception. Using a more powerful architecture can help your model learn more discriminative features and improve performance.\n",
        "\n",
        "# Fine-tune a pre-trained model: Pre-trained models have already been trained on a large dataset and can be fine-tuned for your specific task. Fine-tuning can help your model learn task-specific features and improve performance.\n",
        "\n",
        "# Use transfer learning: Transfer learning involves using the features learned by a pre-trained model and applying them to a new task. This can be an effective way to improve performance on a new task, particularly if you have a limited amount of training data.\n",
        "\n",
        "# Experiment with different hyperparameters: Hyperparameters are settings that determine the model's behavior and performance. You can try tuning different hyperparameters, such as the learning rate, batch size, and optimization algorithm, to see if they have an impact on your model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bZ9Oa5OgU1xk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/go', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/.DS_Store', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/stopLeft', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/warningLeft', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/goForward', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/stop', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/warning', '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/goLeft']\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "def listPaths(path):\n",
        "  pathList = []\n",
        "  for folder in os.listdir(path):\n",
        "    if folder == '.ipynb_checkpoints':\n",
        "      continue\n",
        "    pathList.append(path + '/' + folder)\n",
        "  return pathList\n",
        "\n",
        "print(listPaths('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwcfMd8aFeJg",
        "outputId": "bfdac321-5442-4e5d-8c58-1a1245f7f5e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 40757 files belonging to 7 classes.\n",
            "Found 5096 files belonging to 7 classes.\n",
            "Found 5098 files belonging to 7 classes.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.python.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "train_data_dir = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train'\n",
        "test_data_dir = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test'\n",
        "val_data_dir = '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/val'\n",
        " \n",
        "img_height = 224\n",
        "img_width = 224\n",
        "batch_size=32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  val_data_dir,\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iulhOh93SA-C",
        "outputId": "d44667c4-27d4-45bb-a93a-0202de3c84f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['go', 'goForward', 'goLeft', 'stop', 'stopLeft', 'warning', 'warningLeft']\n"
          ]
        }
      ],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "G_Ihq_2YSIxg"
      },
      "outputs": [],
      "source": [
        "normalization_layer = layers.Rescaling(1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B998lB9ZSRpr",
        "outputId": "d9db8cb4-88e5-4500-e7d9-67b997dd7fbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0 1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-01-09 17:43:11.919860: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        }
      ],
      "source": [
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixel values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sVEo5KVSTr4",
        "outputId": "343e7acf-2eb2-4868-c6d4-4d4a82bbda15"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ResNet 50\n",
        "\n",
        "Accuracy: 0.34203296703296704"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resnet_model = Sequential()\n",
        "\n",
        "# pretrained_model= tf.keras.applications.ResNet50(include_top=False,\n",
        "#                    input_shape=(180,180,3),\n",
        "#                    pooling='avg',classes=7,\n",
        "#                    weights='imagenet')\n",
        "# for layer in pretrained_model.layers:\n",
        "#         layer.trainable=False\n",
        "\n",
        "# resnet_model.add(pretrained_model)\n",
        "# resnet_model.add(Flatten())\n",
        "# resnet_model.add(Dense(512, activation='relu'))\n",
        "# resnet_model.add(Dense(7, activation='softmax'))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## MobileNetV2\n",
        "\n",
        "Accuracy: 0.31456043956043955"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ],
      "source": [
        "mobilenet_v2 = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
        "mobile_net_layers = hub.KerasLayer(mobilenet_v2, input_shape=(224,224,3))\n",
        "mobile_net_layers.trainable = False\n",
        "neural_net = tf.keras.Sequential([mobile_net_layers, tf.keras.layers.Dropout(0.3), tf.keras.layers.Dense(7,activation='softmax')])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## RegNet"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiEFPD6-Sfgc",
        "outputId": "f3d089d0-5357-4d81-e050-1cba1bae7198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 1280)              2257984   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 7)                 8967      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,266,951\n",
            "Trainable params: 8,967\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "neural_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "i8jrXpwvSkIS"
      },
      "outputs": [],
      "source": [
        "# vgg_model.compile(optimizer='adam',loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
        "\n",
        "neural_net.compile(optimizer='Adam', loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "moEFn9SzSoFn",
        "outputId": "870fc6df-3c16-4c3b-ec86-249614b7e896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/manavgurnani21/anaconda3/lib/python3.9/site-packages/keras/backend.py:5582: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1274/1274 [==============================] - 313s 244ms/step - loss: 0.6983 - accuracy: 0.7589 - val_loss: 1.7197 - val_accuracy: 0.3970\n",
            "Epoch 2/10\n",
            "1274/1274 [==============================] - 295s 231ms/step - loss: 0.5242 - accuracy: 0.8183 - val_loss: 1.8201 - val_accuracy: 0.3937\n",
            "Epoch 3/10\n",
            "1274/1274 [==============================] - 275s 216ms/step - loss: 0.4953 - accuracy: 0.8262 - val_loss: 2.0851 - val_accuracy: 0.3809\n",
            "Epoch 4/10\n",
            "1274/1274 [==============================] - 274s 215ms/step - loss: 0.4792 - accuracy: 0.8297 - val_loss: 2.1289 - val_accuracy: 0.3951\n",
            "Epoch 5/10\n",
            "1274/1274 [==============================] - 281s 221ms/step - loss: 0.4712 - accuracy: 0.8338 - val_loss: 2.2695 - val_accuracy: 0.4051\n",
            "Epoch 6/10\n",
            "1274/1274 [==============================] - 313s 246ms/step - loss: 0.4621 - accuracy: 0.8362 - val_loss: 2.3996 - val_accuracy: 0.3750\n",
            "Epoch 7/10\n",
            "1274/1274 [==============================] - 310s 243ms/step - loss: 0.4554 - accuracy: 0.8369 - val_loss: 2.5548 - val_accuracy: 0.3670\n",
            "Epoch 8/10\n",
            "1274/1274 [==============================] - 282s 221ms/step - loss: 0.4576 - accuracy: 0.8357 - val_loss: 2.5518 - val_accuracy: 0.3599\n",
            "Epoch 9/10\n",
            "1274/1274 [==============================] - 279s 219ms/step - loss: 0.4528 - accuracy: 0.8367 - val_loss: 2.4295 - val_accuracy: 0.4164\n",
            "Epoch 10/10\n",
            "1274/1274 [==============================] - 284s 223ms/step - loss: 0.4512 - accuracy: 0.8376 - val_loss: 2.6015 - val_accuracy: 0.4056\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "mobile_history = neural_net.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=10,\n",
        "  callbacks=[callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10\n"
          ]
        }
      ],
      "source": [
        "print(len(mobile_history.history['loss']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# resnet_model = keras.models.load_model('/Users/manavgurnani21/Downloads/Trained_Models/Experiment_3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "U4-bmNNnyqeZ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "160/160 [==============================] - 32s 198ms/step\n",
            "[3.5305716e-02 7.3770411e-06 3.5504377e-03 8.4403068e-01 1.1705816e-01\n",
            " 4.7640318e-05 1.1382637e-11]\n"
          ]
        }
      ],
      "source": [
        "pred=mobile_history.model.predict(test_ds)\n",
        "print(pred[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig1 = plt.gcf()\n",
        "plt.plot(mobile_history.history['accuracy'])\n",
        "plt.plot(mobile_history.history['val_accuracy'])\n",
        "plt.axis(ymin=0.4,ymax=1)\n",
        "plt.grid()\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.legend(['train', 'validation'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5096\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "all_image_path_test = []\n",
        "\n",
        "for folder in listPaths('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test'):\n",
        "    if folder != '/Users/manavgurnani21/Downloads/content/cropped_images_randomized/test/.DS_Store':\n",
        "        for file in listPaths(folder):\n",
        "            all_image_path_test.append(file.split('/')[-2])\n",
        "\n",
        "print(len(all_image_path_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The accuracy of this model is: 0.31456043956043955\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "pred_np = np.asarray(pred)\n",
        "\n",
        "i = 0\n",
        "correct = 0\n",
        "for image_output in pred_np:\n",
        "    predicted_class_name = class_names[np.argmax(image_output)]\n",
        "    if(predicted_class_name == all_image_path_test[i]):\n",
        "        correct += 1\n",
        "    i += 1\n",
        "\n",
        "accuracy = correct / len(all_image_path_test)\n",
        "\n",
        "print(\"The accuracy of this model is:\", accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras.models import save_model\n",
        "\n",
        "# keras.models.save_model(resnet_model,'/Users/manavgurnani21/Downloads/Trained_Models/Experiment_16')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljj5YNyOnf6X"
      },
      "source": [
        "## Agenda for 10/18\n",
        "\n",
        "- sort out issue with random shuffle function (ask about cropping time)\n",
        "- find way to convert images to dataset\n",
        "  - ask why we need singular class folders\n",
        "\n",
        "Goals for the next two weeks:\n",
        "- run experiments (and caputre results)\n",
        "- finish research paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_6612/1493919654.py:12: FutureWarning: `multichannel` is a deprecated argument name for `match_histograms`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  matched = match_histograms(image, reference, multichannel=True)\n",
            "/var/folders/6k/yg9y73qs2hz37v5r2l39pt0m0000gn/T/ipykernel_6612/1285761232.py:3: RuntimeWarning: divide by zero encountered in log\n",
            "  log_image = c * (np.log(image + 1))\n"
          ]
        }
      ],
      "source": [
        "# import required module\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def applyTransformation(directory):\n",
        "    # iterate over files in\n",
        "    # that directory\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for filename in files:\n",
        "            if(filename.__contains__('.DS_Store') == False):\n",
        "                img2 = cv2.imread(os.path.join(root, filename))\n",
        "                new = specification(os.path.join(root, filename))\n",
        "                new_2 = histogram_equalization(new)\n",
        "                new_3 = log_inverse(new_2)\n",
        "                new_4 = gamma(new_3, 0.25)\n",
        "                cv2.imwrite(os.path.join(root, filename), new_4)\n",
        "\n",
        "applyTransformation('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/train')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 1: Hist. Equalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def histogram_equalization(img_in):\n",
        "# segregate color streams\n",
        "    b,g,r = cv2.split(img_in)\n",
        "    h_b, bin_b = np.histogram(b.flatten(), 256, [0, 256])\n",
        "    h_g, bin_g = np.histogram(g.flatten(), 256, [0, 256])\n",
        "    h_r, bin_r = np.histogram(r.flatten(), 256, [0, 256])\n",
        "# calculate cdf    \n",
        "    cdf_b = np.cumsum(h_b)  \n",
        "    cdf_g = np.cumsum(h_g)\n",
        "    cdf_r = np.cumsum(h_r)\n",
        "    \n",
        "# mask all pixels with value=0 and replace it with mean of the pixel values \n",
        "    cdf_m_b = np.ma.masked_equal(cdf_b,0)\n",
        "    cdf_m_b = (cdf_m_b - cdf_m_b.min())*255/(cdf_m_b.max()-cdf_m_b.min())\n",
        "    cdf_final_b = np.ma.filled(cdf_m_b,0).astype('uint8')\n",
        "  \n",
        "    cdf_m_g = np.ma.masked_equal(cdf_g,0)\n",
        "    cdf_m_g = (cdf_m_g - cdf_m_g.min())*255/(cdf_m_g.max()-cdf_m_g.min())\n",
        "    cdf_final_g = np.ma.filled(cdf_m_g,0).astype('uint8')\n",
        "    cdf_m_r = np.ma.masked_equal(cdf_r,0)\n",
        "    cdf_m_r = (cdf_m_r - cdf_m_r.min())*255/(cdf_m_r.max()-cdf_m_r.min())\n",
        "    cdf_final_r = np.ma.filled(cdf_m_r,0).astype('uint8')\n",
        "# merge the images in the three channels\n",
        "    img_b = cdf_final_b[b]\n",
        "    img_g = cdf_final_g[g]\n",
        "    img_r = cdf_final_r[r]\n",
        "  \n",
        "    img_out = cv2.merge((img_b, img_g, img_r))\n",
        "# validation\n",
        "    equ_b = cv2.equalizeHist(b)\n",
        "    equ_g = cv2.equalizeHist(g)\n",
        "    equ_r = cv2.equalizeHist(r)\n",
        "    equ = cv2.merge((equ_b, equ_g, equ_r))\n",
        "    #print(equ)\n",
        "    #cv2.imwrite('output_name.png', equ)\n",
        "    return img_out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 2: Logarithm and Inverse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_inverse(image):\n",
        "    c = 255 / np.log(1 + np.max(image))\n",
        "    log_image = c * (np.log(image + 1))\n",
        "    \n",
        "    # Specify the data type so that\n",
        "    # float value will be converted to int\n",
        "    log_image = np.array(log_image, dtype = np.uint8)\n",
        "\n",
        "    img = cv2.cvtColor(log_image, cv2.COLOR_BGR2RGB)\n",
        "    colored_negative = abs(255-img)\n",
        "    return colored_negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 3: Gamma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gamma(src, gamma):\n",
        "    invGamma = 1 / gamma\n",
        "\n",
        "    table = [((i / 255) ** invGamma) * 255 for i in range(256)]\n",
        "    table = np.array(table, np.uint8)\n",
        "\n",
        "    return cv2.LUT(src, table)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Experiment 4: Specification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from skimage import data\n",
        "from skimage import exposure\n",
        "from skimage.exposure import match_histograms\n",
        "from PIL import Image\n",
        "\n",
        "def specification(path):\n",
        "    reference_unsized = cv2.cvtColor(cv2.imread('/Users/manavgurnani21/Downloads/content/cropped_images_randomized/Colour-Wheel-Rainbow-Spectrum-Color-Wheel-1740381.jpg'), cv2.COLOR_BGR2RGB)\n",
        "    image = cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
        "    reference = cv2.resize(reference_unsized, (image.shape[1], image.shape[0]))\n",
        "    matched = match_histograms(image, reference, multichannel=True)\n",
        "    return matched"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "RuEeyqzznnZm",
        "MdOUu5ltoUJ2",
        "W_GziBHlH4g5",
        "XRdQUObMsW-Q",
        "wrV_68rxug_v",
        "be2KCYipPzis",
        "ESKRu9hLzs1V",
        "LYDgT7CPTUYb"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "7dd6fc5c128be82ef760667744b68c23ef537939cb516a15f2e77205952262b8"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
